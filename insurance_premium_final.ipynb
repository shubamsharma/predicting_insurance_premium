{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-95-12a014c06242>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-95-12a014c06242>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    import matplotlib import pyplot\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from math import sqrt \n",
    "from sklearn.model_selection import cross_val_predict  \n",
    "from sklearn.metrics import r2_score, mean_squared_error  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sex</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bmi</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>children</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoker</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>region</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expenses</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  column_name column_type\n",
       "0         age       int64\n",
       "1         sex       int64\n",
       "2         bmi     float64\n",
       "3    children       int64\n",
       "4      smoker       int64\n",
       "5      region      object\n",
       "6    expenses     float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"insurance.csv\")\n",
    "\n",
    "sex_map = {\"female\" : 0, \"male\" : 1}\n",
    "smoker_map = {\"yes\" : 0, \"no\" : 1}\n",
    "data['sex'] = data.sex.map(sex_map)\n",
    "data['smoker'] = data.smoker.map(smoker_map)\n",
    "\n",
    "data_type = data.dtypes.reset_index()\n",
    "data_type.columns = [\"column_name\",\"column_type\"]\n",
    "data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_my_data(data,scale = False, polyfeature = False):\n",
    "    \n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    print(data_copy.dtypes)\n",
    "    temp_data_type = data.dtypes.reset_index()\n",
    "    temp_data_type.columns = [\"column_name\",\"column_type\"]\n",
    "    \n",
    "    if \"object\" in temp_data_type.column_type.tolist():\n",
    "        data_copy = pd.get_dummies(data_copy, columns = data_type[data_type.column_type == \"object\"].column_name.tolist())\n",
    "\n",
    "    data_x = data_copy.drop([\"expenses\"],axis = 1)\n",
    "    data_y = data_copy[\"expenses\"]\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(data_x,data_y,shuffle=True, random_state=0)\n",
    "    \n",
    "    train_x_copy = train_x.copy()\n",
    "    if scale == True:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_x_copy.values)\n",
    "        train_x = pd.DataFrame(scaler.transform(train_x), columns=train_x.columns)\n",
    "        test_x = pd.DataFrame(scaler.transform(test_x), columns=test_x.columns)\n",
    "\n",
    "    if polyfeature == True:\n",
    "        polynomial_features = PolynomialFeatures(degree=3)  \n",
    "        train_x = pd.DataFrame(polynomial_features.fit_transform(train_x))\n",
    "        test_x = pd.DataFrame(polynomial_features.fit_transform(test_x))\n",
    "        \n",
    "    data_x = pd.concat([train_x, test_x], axis=0)\n",
    "    data_y = pd.concat([train_y, test_y], axis=0)\n",
    "    \n",
    "    print(data_x.columns)\n",
    "    \n",
    "    return train_x,test_x, train_y, test_y, data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age           int64\n",
      "sex           int64\n",
      "bmi         float64\n",
      "children      int64\n",
      "smoker        int64\n",
      "region       object\n",
      "expenses    float64\n",
      "dtype: object\n",
      "RangeIndex(start=0, stop=220, step=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1003, 220), (335, 220), (1003,), (335,), (1338, 220), (1338,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x,test_x, train_y, test_y, data_x, data_y = preprocess_my_data(data,scale = True, polyfeature = True)\n",
    "train_x.shape,test_x.shape, train_y.shape, test_y.shape, data_x.shape, data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.51485</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-0.18005</td>\n",
       "      <td>-0.06361</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>-0.54240</td>\n",
       "      <td>-0.55777</td>\n",
       "      <td>1.62298</td>\n",
       "      <td>-0.59309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17353</td>\n",
       "      <td>0.50493</td>\n",
       "      <td>-0.18452</td>\n",
       "      <td>-1.46921</td>\n",
       "      <td>0.53689</td>\n",
       "      <td>-0.19620</td>\n",
       "      <td>4.27502</td>\n",
       "      <td>-1.56223</td>\n",
       "      <td>0.57089</td>\n",
       "      <td>-0.20862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.54875</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-1.39983</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>1.84367</td>\n",
       "      <td>-0.55777</td>\n",
       "      <td>-0.61615</td>\n",
       "      <td>-0.59309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17353</td>\n",
       "      <td>-0.19169</td>\n",
       "      <td>-0.18452</td>\n",
       "      <td>-0.21175</td>\n",
       "      <td>-0.20383</td>\n",
       "      <td>-0.19620</td>\n",
       "      <td>-0.23392</td>\n",
       "      <td>-0.22516</td>\n",
       "      <td>-0.21673</td>\n",
       "      <td>-0.20862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.43992</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>-0.98254</td>\n",
       "      <td>-0.06361</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>-0.54240</td>\n",
       "      <td>-0.55777</td>\n",
       "      <td>-0.61615</td>\n",
       "      <td>1.68609</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17353</td>\n",
       "      <td>-0.19169</td>\n",
       "      <td>0.52456</td>\n",
       "      <td>-0.21175</td>\n",
       "      <td>0.57946</td>\n",
       "      <td>-1.58570</td>\n",
       "      <td>-0.23392</td>\n",
       "      <td>0.64011</td>\n",
       "      <td>-1.75166</td>\n",
       "      <td>4.79342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.36876</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-1.01464</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>-1.98517</td>\n",
       "      <td>-0.54240</td>\n",
       "      <td>-0.55777</td>\n",
       "      <td>1.62298</td>\n",
       "      <td>-0.59309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17353</td>\n",
       "      <td>0.50493</td>\n",
       "      <td>-0.18452</td>\n",
       "      <td>-1.46921</td>\n",
       "      <td>0.53689</td>\n",
       "      <td>-0.19620</td>\n",
       "      <td>4.27502</td>\n",
       "      <td>-1.56223</td>\n",
       "      <td>0.57089</td>\n",
       "      <td>-0.20862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.94181</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-1.36773</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>-0.54240</td>\n",
       "      <td>1.79284</td>\n",
       "      <td>-0.61615</td>\n",
       "      <td>-0.59309</td>\n",
       "      <td>...</td>\n",
       "      <td>5.76271</td>\n",
       "      <td>-1.98049</td>\n",
       "      <td>-1.90635</td>\n",
       "      <td>0.68064</td>\n",
       "      <td>0.65516</td>\n",
       "      <td>0.63064</td>\n",
       "      <td>-0.23392</td>\n",
       "      <td>-0.22516</td>\n",
       "      <td>-0.21673</td>\n",
       "      <td>-0.20862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.87065</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>-0.75784</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>1.84367</td>\n",
       "      <td>-0.55777</td>\n",
       "      <td>-0.61615</td>\n",
       "      <td>-0.59309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17353</td>\n",
       "      <td>-0.19169</td>\n",
       "      <td>-0.18452</td>\n",
       "      <td>-0.21175</td>\n",
       "      <td>-0.20383</td>\n",
       "      <td>-0.19620</td>\n",
       "      <td>-0.23392</td>\n",
       "      <td>-0.22516</td>\n",
       "      <td>-0.21673</td>\n",
       "      <td>-0.20862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.19673</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>0.84713</td>\n",
       "      <td>0.76493</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>-0.54240</td>\n",
       "      <td>-0.55777</td>\n",
       "      <td>1.62298</td>\n",
       "      <td>-0.59309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17353</td>\n",
       "      <td>0.50493</td>\n",
       "      <td>-0.18452</td>\n",
       "      <td>-1.46921</td>\n",
       "      <td>0.53689</td>\n",
       "      <td>-0.19620</td>\n",
       "      <td>4.27502</td>\n",
       "      <td>-1.56223</td>\n",
       "      <td>0.57089</td>\n",
       "      <td>-0.20862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.05442</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>-0.90229</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>-0.54240</td>\n",
       "      <td>-0.55777</td>\n",
       "      <td>1.62298</td>\n",
       "      <td>-0.59309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17353</td>\n",
       "      <td>0.50493</td>\n",
       "      <td>-0.18452</td>\n",
       "      <td>-1.46921</td>\n",
       "      <td>0.53689</td>\n",
       "      <td>-0.19620</td>\n",
       "      <td>4.27502</td>\n",
       "      <td>-1.56223</td>\n",
       "      <td>0.57089</td>\n",
       "      <td>-0.20862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.43992</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>0.76688</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>-0.54240</td>\n",
       "      <td>1.79284</td>\n",
       "      <td>-0.61615</td>\n",
       "      <td>-0.59309</td>\n",
       "      <td>...</td>\n",
       "      <td>5.76271</td>\n",
       "      <td>-1.98049</td>\n",
       "      <td>-1.90635</td>\n",
       "      <td>0.68064</td>\n",
       "      <td>0.65516</td>\n",
       "      <td>0.63064</td>\n",
       "      <td>-0.23392</td>\n",
       "      <td>-0.22516</td>\n",
       "      <td>-0.21673</td>\n",
       "      <td>-0.20862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.44369</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-1.96157</td>\n",
       "      <td>-0.06361</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>-0.54240</td>\n",
       "      <td>-0.55777</td>\n",
       "      <td>-0.61615</td>\n",
       "      <td>1.68609</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17353</td>\n",
       "      <td>-0.19169</td>\n",
       "      <td>0.52456</td>\n",
       "      <td>-0.21175</td>\n",
       "      <td>0.57946</td>\n",
       "      <td>-1.58570</td>\n",
       "      <td>-0.23392</td>\n",
       "      <td>0.64011</td>\n",
       "      <td>-1.75166</td>\n",
       "      <td>4.79342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1003 rows × 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2        3        4        5        6        7    \\\n",
       "0    1.00000 -0.51485 -0.98516 -0.18005 -0.06361  0.50374 -0.54240 -0.55777   \n",
       "1    1.00000  1.54875 -0.98516 -1.39983 -0.89214  0.50374  1.84367 -0.55777   \n",
       "2    1.00000 -1.43992  1.01507 -0.98254 -0.06361  0.50374 -0.54240 -0.55777   \n",
       "3    1.00000 -1.36876 -0.98516 -1.01464 -0.89214 -1.98517 -0.54240 -0.55777   \n",
       "4    1.00000 -0.94181 -0.98516 -1.36773 -0.89214  0.50374 -0.54240  1.79284   \n",
       "...      ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "998  1.00000 -0.87065  1.01507 -0.75784 -0.89214  0.50374  1.84367 -0.55777   \n",
       "999  1.00000  0.19673  1.01507  0.84713  0.76493  0.50374 -0.54240 -0.55777   \n",
       "1000 1.00000  0.05442  1.01507 -0.90229 -0.89214  0.50374 -0.54240 -0.55777   \n",
       "1001 1.00000 -1.43992  1.01507  0.76688 -0.89214  0.50374 -0.54240  1.79284   \n",
       "1002 1.00000 -0.44369 -0.98516 -1.96157 -0.06361  0.50374 -0.54240 -0.55777   \n",
       "\n",
       "          8        9    ...      210      211      212      213      214  \\\n",
       "0     1.62298 -0.59309  ... -0.17353  0.50493 -0.18452 -1.46921  0.53689   \n",
       "1    -0.61615 -0.59309  ... -0.17353 -0.19169 -0.18452 -0.21175 -0.20383   \n",
       "2    -0.61615  1.68609  ... -0.17353 -0.19169  0.52456 -0.21175  0.57946   \n",
       "3     1.62298 -0.59309  ... -0.17353  0.50493 -0.18452 -1.46921  0.53689   \n",
       "4    -0.61615 -0.59309  ...  5.76271 -1.98049 -1.90635  0.68064  0.65516   \n",
       "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "998  -0.61615 -0.59309  ... -0.17353 -0.19169 -0.18452 -0.21175 -0.20383   \n",
       "999   1.62298 -0.59309  ... -0.17353  0.50493 -0.18452 -1.46921  0.53689   \n",
       "1000  1.62298 -0.59309  ... -0.17353  0.50493 -0.18452 -1.46921  0.53689   \n",
       "1001 -0.61615 -0.59309  ...  5.76271 -1.98049 -1.90635  0.68064  0.65516   \n",
       "1002 -0.61615  1.68609  ... -0.17353 -0.19169  0.52456 -0.21175  0.57946   \n",
       "\n",
       "          215      216      217      218      219  \n",
       "0    -0.19620  4.27502 -1.56223  0.57089 -0.20862  \n",
       "1    -0.19620 -0.23392 -0.22516 -0.21673 -0.20862  \n",
       "2    -1.58570 -0.23392  0.64011 -1.75166  4.79342  \n",
       "3    -0.19620  4.27502 -1.56223  0.57089 -0.20862  \n",
       "4     0.63064 -0.23392 -0.22516 -0.21673 -0.20862  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "998  -0.19620 -0.23392 -0.22516 -0.21673 -0.20862  \n",
       "999  -0.19620  4.27502 -1.56223  0.57089 -0.20862  \n",
       "1000 -0.19620  4.27502 -1.56223  0.57089 -0.20862  \n",
       "1001  0.63064 -0.23392 -0.22516 -0.21673 -0.20862  \n",
       "1002 -1.58570 -0.23392  0.64011 -1.75166  4.79342  \n",
       "\n",
       "[1003 rows x 220 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"                     Linear Regression\": LinearRegression(),\n",
    "    \"                   K-Nearest Neighbors\": KNeighborsRegressor(),\n",
    "    \"                        Neural Network\": MLPRegressor(),\n",
    "    \"Support Vector Machine (Linear Kernel)\": LinearSVR(),\n",
    "    \"   Support Vector Machine (RBF Kernel)\": SVR(),\n",
    "    \"                         Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"                         Random Forest\": RandomForestRegressor(),\n",
    "    \"                     Gradient Boosting\": GradientBoostingRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_summary(model, model_name, cvn=20):\n",
    "    \n",
    "    print(model_name)\n",
    "    \n",
    "    y_pred_model_train = model.predict(train_x)\n",
    "    y_pred_model_test = model.predict(test_x)\n",
    "    \n",
    "    accuracy_model_train = r2_score(train_y, y_pred_model_train)\n",
    "    print(\"Training Accuracy: \", accuracy_model_train)\n",
    "    \n",
    "    accuracy_model_test = r2_score(test_y, y_pred_model_test)\n",
    "    print(\"Testing Accuracy: \", accuracy_model_test)\n",
    "    \n",
    "    RMSE_model_train = sqrt(mean_squared_error(train_y, y_pred_model_train))\n",
    "    print(\"RMSE for Training Data: \", RMSE_model_train)\n",
    "    \n",
    "    RMSE_model_test = sqrt(mean_squared_error(test_y, y_pred_model_test))\n",
    "    print(\"RMSE for Testing Data: \", RMSE_model_test)\n",
    "    \n",
    "    y_pred_cv_model = cross_val_predict(model, data_x, data_y, cv=cvn)\n",
    "    accuracy_cv_model = r2_score(data_y, y_pred_cv_model)\n",
    "    print(\"Accuracy for\", cvn,\"- Fold Cross Predicted: \", accuracy_cv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Linear Regression trained.\n",
      "                   K-Nearest Neighbors trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Neural Network trained.\n",
      "Support Vector Machine (Linear Kernel) trained.\n",
      "   Support Vector Machine (RBF Kernel) trained.\n",
      "                         Decision Tree trained.\n",
      "                         Random Forest trained.\n",
      "                     Gradient Boosting trained.\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(train_x, train_y)\n",
    "    print(name + \" trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Linear Regression\n",
      "Training Accuracy:  0.8432726770198031\n",
      "Testing Accuracy:  0.8623318488726837\n",
      "RMSE for Training Data:  4732.361579904418\n",
      "RMSE for Testing Data:  4655.504094371313\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.8272064069440559\n",
      "                   K-Nearest Neighbors\n",
      "Training Accuracy:  0.8443574653320628\n",
      "Testing Accuracy:  0.8335135385089941\n",
      "RMSE for Training Data:  4715.955619597897\n",
      "RMSE for Testing Data:  5119.640127937328\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.7890304329898132\n",
      "                        Neural Network\n",
      "Training Accuracy:  -0.2824947697815319\n",
      "Testing Accuracy:  -0.25108028513013614\n",
      "RMSE for Training Data:  13537.3408328235\n",
      "RMSE for Testing Data:  14034.358404165494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 20 - Fold Cross Predicted:  0.19877669515625684\n",
      "Support Vector Machine (Linear Kernel)\n",
      "Training Accuracy:  0.5835310602328199\n",
      "Testing Accuracy:  0.6308119404808208\n",
      "RMSE for Training Data:  7714.306157320669\n",
      "RMSE for Testing Data:  7623.840401975987\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.6475386144539015\n",
      "   Support Vector Machine (RBF Kernel)\n",
      "Training Accuracy:  -0.09308208648872829\n",
      "Testing Accuracy:  -0.09471123023235006\n",
      "RMSE for Training Data:  12497.753385427415\n",
      "RMSE for Testing Data:  13128.036020672389\n",
      "Accuracy for 20 - Fold Cross Predicted:  -0.10080778579105854\n",
      "                         Decision Tree\n",
      "Training Accuracy:  0.9994547913426406\n",
      "Testing Accuracy:  0.7535835921689917\n",
      "RMSE for Training Data:  279.11741463181363\n",
      "RMSE for Testing Data:  6228.518864184397\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.6871260921990181\n",
      "                         Random Forest\n",
      "Training Accuracy:  0.9745244281579322\n",
      "Testing Accuracy:  0.8737126816821208\n",
      "RMSE for Training Data:  1907.9523870362864\n",
      "RMSE for Testing Data:  4458.921674368369\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.8364313884665487\n",
      "                     Gradient Boosting\n",
      "Training Accuracy:  0.9315309723091715\n",
      "Testing Accuracy:  0.8670993319476615\n",
      "RMSE for Training Data:  3127.89843200407\n",
      "RMSE for Testing Data:  4574.183205232021\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.8451985990389655\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model_summary(model, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['region'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age           int64\n",
      "sex           int64\n",
      "bmi         float64\n",
      "children      int64\n",
      "smoker        int64\n",
      "expenses    float64\n",
      "dtype: object\n",
      "RangeIndex(start=0, stop=56, step=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1003, 56), (335, 56), (1003,), (335,), (1338, 56), (1338,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x,test_x, train_y, test_y, data_x, data_y = preprocess_my_data(data,scale = True, polyfeature = True)\n",
    "train_x.shape,test_x.shape, train_y.shape, test_y.shape, data_x.shape, data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.51485</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-0.18005</td>\n",
       "      <td>-0.06361</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>0.26507</td>\n",
       "      <td>0.50721</td>\n",
       "      <td>0.09270</td>\n",
       "      <td>0.03275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00584</td>\n",
       "      <td>-0.00206</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>-0.00073</td>\n",
       "      <td>0.00577</td>\n",
       "      <td>-0.04569</td>\n",
       "      <td>-0.00026</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>-0.01614</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.54875</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-1.39983</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>2.39861</td>\n",
       "      <td>-1.52576</td>\n",
       "      <td>-2.16798</td>\n",
       "      <td>-1.38170</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.74301</td>\n",
       "      <td>-1.74818</td>\n",
       "      <td>0.98709</td>\n",
       "      <td>-1.11416</td>\n",
       "      <td>0.62909</td>\n",
       "      <td>-0.35521</td>\n",
       "      <td>-0.71008</td>\n",
       "      <td>0.40093</td>\n",
       "      <td>-0.22638</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.43992</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>-0.98254</td>\n",
       "      <td>-0.06361</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>2.07336</td>\n",
       "      <td>-1.46161</td>\n",
       "      <td>1.41477</td>\n",
       "      <td>0.09159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.94852</td>\n",
       "      <td>-0.06140</td>\n",
       "      <td>0.48630</td>\n",
       "      <td>-0.00398</td>\n",
       "      <td>0.03148</td>\n",
       "      <td>-0.24932</td>\n",
       "      <td>-0.00026</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>-0.01614</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.36876</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-1.01464</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>-1.98517</td>\n",
       "      <td>1.87350</td>\n",
       "      <td>1.34844</td>\n",
       "      <td>1.38879</td>\n",
       "      <td>1.22113</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.04456</td>\n",
       "      <td>-0.91845</td>\n",
       "      <td>-2.04371</td>\n",
       "      <td>-0.80757</td>\n",
       "      <td>-1.79698</td>\n",
       "      <td>-3.99857</td>\n",
       "      <td>-0.71008</td>\n",
       "      <td>-1.58004</td>\n",
       "      <td>-3.51584</td>\n",
       "      <td>-7.82332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.94181</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-1.36773</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>0.88700</td>\n",
       "      <td>0.92782</td>\n",
       "      <td>1.28814</td>\n",
       "      <td>0.84023</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.55860</td>\n",
       "      <td>-1.66893</td>\n",
       "      <td>0.94233</td>\n",
       "      <td>-1.08861</td>\n",
       "      <td>0.61467</td>\n",
       "      <td>-0.34706</td>\n",
       "      <td>-0.71008</td>\n",
       "      <td>0.40093</td>\n",
       "      <td>-0.22638</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.87065</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>-0.75784</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>0.75803</td>\n",
       "      <td>-0.88377</td>\n",
       "      <td>0.65981</td>\n",
       "      <td>0.77674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.43525</td>\n",
       "      <td>-0.51238</td>\n",
       "      <td>0.28931</td>\n",
       "      <td>-0.60318</td>\n",
       "      <td>0.34058</td>\n",
       "      <td>-0.19230</td>\n",
       "      <td>-0.71008</td>\n",
       "      <td>0.40093</td>\n",
       "      <td>-0.22638</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.19673</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>0.84713</td>\n",
       "      <td>0.76493</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>0.03870</td>\n",
       "      <td>0.19970</td>\n",
       "      <td>0.16666</td>\n",
       "      <td>0.15049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60793</td>\n",
       "      <td>0.54894</td>\n",
       "      <td>0.36150</td>\n",
       "      <td>0.49567</td>\n",
       "      <td>0.32642</td>\n",
       "      <td>0.21496</td>\n",
       "      <td>0.44758</td>\n",
       "      <td>0.29475</td>\n",
       "      <td>0.19410</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.05442</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>-0.90229</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>0.00296</td>\n",
       "      <td>0.05524</td>\n",
       "      <td>-0.04910</td>\n",
       "      <td>-0.04855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.73458</td>\n",
       "      <td>-0.72632</td>\n",
       "      <td>0.41010</td>\n",
       "      <td>-0.71815</td>\n",
       "      <td>0.40549</td>\n",
       "      <td>-0.22896</td>\n",
       "      <td>-0.71008</td>\n",
       "      <td>0.40093</td>\n",
       "      <td>-0.22638</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.43992</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>0.76688</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>2.07336</td>\n",
       "      <td>-1.46161</td>\n",
       "      <td>-1.10425</td>\n",
       "      <td>1.28461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45101</td>\n",
       "      <td>-0.52468</td>\n",
       "      <td>0.29625</td>\n",
       "      <td>0.61038</td>\n",
       "      <td>-0.34464</td>\n",
       "      <td>0.19460</td>\n",
       "      <td>-0.71008</td>\n",
       "      <td>0.40093</td>\n",
       "      <td>-0.22638</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.44369</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-1.96157</td>\n",
       "      <td>-0.06361</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>0.19687</td>\n",
       "      <td>0.43711</td>\n",
       "      <td>0.87034</td>\n",
       "      <td>0.02822</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.54767</td>\n",
       "      <td>-0.24474</td>\n",
       "      <td>1.93826</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>0.06285</td>\n",
       "      <td>-0.49775</td>\n",
       "      <td>-0.00026</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>-0.01614</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1003 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1        2        3        4        5       6        7   \\\n",
       "0    1.00000 -0.51485 -0.98516 -0.18005 -0.06361  0.50374 0.26507  0.50721   \n",
       "1    1.00000  1.54875 -0.98516 -1.39983 -0.89214  0.50374 2.39861 -1.52576   \n",
       "2    1.00000 -1.43992  1.01507 -0.98254 -0.06361  0.50374 2.07336 -1.46161   \n",
       "3    1.00000 -1.36876 -0.98516 -1.01464 -0.89214 -1.98517 1.87350  1.34844   \n",
       "4    1.00000 -0.94181 -0.98516 -1.36773 -0.89214  0.50374 0.88700  0.92782   \n",
       "...      ...      ...      ...      ...      ...      ...     ...      ...   \n",
       "998  1.00000 -0.87065  1.01507 -0.75784 -0.89214  0.50374 0.75803 -0.88377   \n",
       "999  1.00000  0.19673  1.01507  0.84713  0.76493  0.50374 0.03870  0.19970   \n",
       "1000 1.00000  0.05442  1.01507 -0.90229 -0.89214  0.50374 0.00296  0.05524   \n",
       "1001 1.00000 -1.43992  1.01507  0.76688 -0.89214  0.50374 2.07336 -1.46161   \n",
       "1002 1.00000 -0.44369 -0.98516 -1.96157 -0.06361  0.50374 0.19687  0.43711   \n",
       "\n",
       "           8        9   ...       46       47       48       49       50  \\\n",
       "0     0.09270  0.03275  ... -0.00584 -0.00206  0.01633 -0.00073  0.00577   \n",
       "1    -2.16798 -1.38170  ... -2.74301 -1.74818  0.98709 -1.11416  0.62909   \n",
       "2     1.41477  0.09159  ... -0.94852 -0.06140  0.48630 -0.00398  0.03148   \n",
       "3     1.38879  1.22113  ... -1.04456 -0.91845 -2.04371 -0.80757 -1.79698   \n",
       "4     1.28814  0.84023  ... -2.55860 -1.66893  0.94233 -1.08861  0.61467   \n",
       "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "998   0.65981  0.77674  ... -0.43525 -0.51238  0.28931 -0.60318  0.34058   \n",
       "999   0.16666  0.15049  ...  0.60793  0.54894  0.36150  0.49567  0.32642   \n",
       "1000 -0.04910 -0.04855  ... -0.73458 -0.72632  0.41010 -0.71815  0.40549   \n",
       "1001 -1.10425  1.28461  ...  0.45101 -0.52468  0.29625  0.61038 -0.34464   \n",
       "1002  0.87034  0.02822  ... -7.54767 -0.24474  1.93826 -0.00794  0.06285   \n",
       "\n",
       "           51       52       53       54       55  \n",
       "0    -0.04569 -0.00026  0.00204 -0.01614  0.12782  \n",
       "1    -0.35521 -0.71008  0.40093 -0.22638  0.12782  \n",
       "2    -0.24932 -0.00026  0.00204 -0.01614  0.12782  \n",
       "3    -3.99857 -0.71008 -1.58004 -3.51584 -7.82332  \n",
       "4    -0.34706 -0.71008  0.40093 -0.22638  0.12782  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "998  -0.19230 -0.71008  0.40093 -0.22638  0.12782  \n",
       "999   0.21496  0.44758  0.29475  0.19410  0.12782  \n",
       "1000 -0.22896 -0.71008  0.40093 -0.22638  0.12782  \n",
       "1001  0.19460 -0.71008  0.40093 -0.22638  0.12782  \n",
       "1002 -0.49775 -0.00026  0.00204 -0.01614  0.12782  \n",
       "\n",
       "[1003 rows x 56 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Linear Regression trained.\n",
      "                   K-Nearest Neighbors trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Neural Network trained.\n",
      "Support Vector Machine (Linear Kernel) trained.\n",
      "   Support Vector Machine (RBF Kernel) trained.\n",
      "                         Decision Tree trained.\n",
      "                         Random Forest trained.\n",
      "                     Gradient Boosting trained.\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(train_x, train_y)\n",
    "    print(name + \" trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Linear Regression\n",
      "Training Accuracy:  0.8355466992767058\n",
      "Testing Accuracy:  0.8814078014426706\n",
      "RMSE for Training Data:  4847.600921326647\n",
      "RMSE for Testing Data:  4320.937984245219\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.8385819063721809\n",
      "                   K-Nearest Neighbors\n",
      "Training Accuracy:  0.85440972069296\n",
      "Testing Accuracy:  0.8589526304010063\n",
      "RMSE for Training Data:  4561.122659922318\n",
      "RMSE for Testing Data:  4712.2949810263635\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.8128251841533437\n",
      "                        Neural Network\n",
      "Training Accuracy:  -0.6010387202071321\n",
      "Testing Accuracy:  -0.5270157036816552\n",
      "RMSE for Training Data:  15125.386452496252\n",
      "RMSE for Testing Data:  15504.9983600325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 20 - Fold Cross Predicted:  -0.303776064826383\n",
      "Support Vector Machine (Linear Kernel)\n",
      "Training Accuracy:  0.3337124671487389\n",
      "Testing Accuracy:  0.3970507879911953\n",
      "RMSE for Training Data:  9757.451597326268\n",
      "RMSE for Testing Data:  9742.946974640805\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.48250976154917535\n",
      "   Support Vector Machine (RBF Kernel)\n",
      "Training Accuracy:  -0.09113611350490647\n",
      "Testing Accuracy:  -0.09261516825444982\n",
      "RMSE for Training Data:  12486.623789344103\n",
      "RMSE for Testing Data:  13115.461763227693\n",
      "Accuracy for 20 - Fold Cross Predicted:  -0.09593033699255282\n",
      "                         Decision Tree\n",
      "Training Accuracy:  0.9994530805400387\n",
      "Testing Accuracy:  0.7230404647398465\n",
      "RMSE for Training Data:  279.5549909455425\n",
      "RMSE for Testing Data:  6603.255988044759\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.6963238320777394\n",
      "                         Random Forest\n",
      "Training Accuracy:  0.9731665261421744\n",
      "Testing Accuracy:  0.8721953824408701\n",
      "RMSE for Training Data:  1958.1412308196036\n",
      "RMSE for Testing Data:  4485.627912094648\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.8315389632773776\n",
      "                     Gradient Boosting\n",
      "Training Accuracy:  0.9176479621568104\n",
      "Testing Accuracy:  0.8881696694842398\n",
      "RMSE for Training Data:  3430.383994049662\n",
      "RMSE for Testing Data:  4195.944906623438\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.8503664728218854\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model_summary(model, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11766., 10190., 48560., 13086., 12346.,  5461.,  2280., 13926.,\n",
       "        8501.,  6973.,  7326., 11452.,  8969.,  5217., 25138., 12279.,\n",
       "       13697.,  5796.,  7691., 25908., 26128., 15174., 10942., 30266.,\n",
       "        4129.,  7169.,  6386.,  9365.,  4612.,  9976.,  8827., 53224.,\n",
       "       13542., 11600., 13432.,  4348., 11071., 37546., 36714.,  2890.,\n",
       "        7060.,  4211., 26172., 47722., 36422.,  6320., 12196.,  8010.,\n",
       "        5900., 13302.,  3396.,  7108., 30992., 45712., 12563.,  5169.,\n",
       "        4874., 10171.,  8294., 14281.,  2681., 40420., 17864., 12084.,\n",
       "       13024., 12016., 24836., 34810.,  6137.,  8901., 13750., 13334.,\n",
       "       20276., 14928., 13493., 13402.,  9193.,  9694., 24594., 47512.,\n",
       "       12143., 55794.,  3784.,  9453., 40686., 22098.,  4516.,  4161.,\n",
       "       14055., 37250.,  7398., 11796.,  3297.,  9923.,  6214.,  6312.,\n",
       "       37778., 33048.,  7014., 11270.,  4007.,  7598.,  6632., 38176.,\n",
       "       29312.,  4364., 12732.,  4289., 12670., 42092., 12875.,  6158.,\n",
       "       10471., 26722., 53756.,  8092.,  3302., 10167., 14564.,  9348.,\n",
       "       40880., 12556., 15069.,  7834.,  9056.,  6588., 27188., 21318.,\n",
       "       52528.,  4536.,  9876.,  5802.,  7628., 10912., 33172., 31674.,\n",
       "       24200., 11198., 22390.,  4348.,  2784., 11796., 12131., 11526.,\n",
       "        5756., 15258., 15343.,  5952.,  1892., 12025.,  7354., 44892.,\n",
       "       11658.,  4812.,  4751.,  8084.,  5254.,  4647., 12260., 11973.,\n",
       "        7021., 12982., 13389., 11528.,  5805.,  7344., 13766.,  7204.,\n",
       "        5360.,  2686.,  6808.,  5361.,  9680.,  4688.,  6431.,  7314.,\n",
       "        4484.,  6914., 37538.,  2058., 13124.,  7994., 12414.,  4780.,\n",
       "        5454., 31990.,  3696.,  4622., 15094., 12138., 38468.,  6242.,\n",
       "        6815., 25612.,  4771.,  2934.,  7565.,  7660.,  7488.,  5676.,\n",
       "       13024., 44326., 14580., 22394.,  6649., 44612.,  4648., 10929.,\n",
       "        7862.,  4303., 10669., 14332.,  6578.,  3309.,  8060.,  2780.,\n",
       "        6854.,  6405., 16479.,  8525.,  7660.,  7956.,  9514.,  3550.,\n",
       "       13110., 13998., 15422., 12767.,  5817.,  3116.,  2909., 10105.,\n",
       "       13560.,  7940.,  6030.,  9096., 10328., 28208.,  7124., 12324.,\n",
       "        6410., 33592.,  9442.,  7966.,  9496., 12233.,  4724.,  9381.,\n",
       "        3082.,  7514., 27614., 40770.,  6496.,  4504.,  2356.,  1736.,\n",
       "        9892.,  2841.,  5373.,  5284.,  7910., 30260., 41022., 17377.,\n",
       "        8000., 11536., 41374.,  9112., 36238.,  3933., 37864.,  7660.,\n",
       "       14579.,  5976., 38632.,  6870., 11199.,  8689.,  5445., 14825.,\n",
       "       12744.,  6296., 13378.,  2417.,  8273.,  7068.,  9275., 25182.,\n",
       "        4227.,  1966.,  3922., 47200., 10240.,  6211., 14683., 13415.,\n",
       "       29902.,  7890.,  6844., 10293.,  3118.,  6260., 11956., 20572.,\n",
       "       14184.,  3171.,  5284.,  9471., 10928., 13486., 26478.,  7272.,\n",
       "       15024.,  2554.,  6979.,  6169.,  9284.,  4079.,  7906., 48080.,\n",
       "        6351.,  5542.,  2788.,  9776.,  4520., 13017., 43116., 17352.,\n",
       "       10890., 44024., 15698.,  6738., 11394.,  7716., 34026.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_prediction = models['                     Linear Regression'].predict(test_x)\n",
    "lr_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0     1.00000\n",
       " 1     1.00000\n",
       " 2     1.00000\n",
       " 3     1.00000\n",
       " 4     1.00000\n",
       "         ...  \n",
       " 330   1.00000\n",
       " 331   1.00000\n",
       " 332   1.00000\n",
       " 333   1.00000\n",
       " 334   1.00000\n",
       " Name: 0, Length: 335, dtype: float64,\n",
       " 9724.53,\n",
       " 11766.0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_in = test_x[0]\n",
    "y_out = test_y.tolist()[0]\n",
    "yhat_out = lr_prediction[0]\n",
    "x_in, y_out, yhat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sum as arraysum\n",
    "sum_errs = arraysum((test_y - lr_prediction)**2)\n",
    "stdev = sqrt(1/(len(test_y)-2) * sum_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Interval: 8494.433\n",
      "95% likelihood that the true value is between 3271.567 and 20260.433\n"
     ]
    }
   ],
   "source": [
    "# calculate prediction interval\n",
    "interval = 1.96 * stdev\n",
    "print('Prediction Interval: %.3f' % interval)\n",
    "lower, upper = yhat_out - interval, yhat_out + interval\n",
    "print('95%% likelihood that the true value is between %.3f and %.3f' % (lower, upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
