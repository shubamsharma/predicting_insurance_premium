{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from math import sqrt \n",
    "from sklearn.model_selection import cross_val_predict  \n",
    "from sklearn.metrics import r2_score, mean_squared_error  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sex</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bmi</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>children</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoker</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>region</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expenses</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  column_name column_type\n",
       "0         age       int64\n",
       "1         sex       int64\n",
       "2         bmi     float64\n",
       "3    children       int64\n",
       "4      smoker       int64\n",
       "5      region      object\n",
       "6    expenses     float64"
      ]
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"insurance.csv\")\n",
    "\n",
    "sex_map = {\"female\" : 0, \"male\" : 1}\n",
    "smoker_map = {\"yes\" : 0, \"no\" : 1}\n",
    "data['sex'] = data.sex.map(sex_map)\n",
    "data['smoker'] = data.smoker.map(smoker_map)\n",
    "\n",
    "data_type = data.dtypes.reset_index()\n",
    "data_type.columns = [\"column_name\",\"column_type\"]\n",
    "data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_my_data(data,scale = False, polyfeature = False):\n",
    "    \n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    print(data_copy.dtypes)\n",
    "    temp_data_type = data.dtypes.reset_index()\n",
    "    temp_data_type.columns = [\"column_name\",\"column_type\"]\n",
    "    \n",
    "    if \"object\" in temp_data_type.column_type.tolist():\n",
    "        data_copy = pd.get_dummies(data_copy, columns = data_type[data_type.column_type == \"object\"].column_name.tolist())\n",
    "\n",
    "    data_x = data_copy.drop([\"expenses\"],axis = 1)\n",
    "    data_y = data_copy[\"expenses\"]\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(data_x,data_y,shuffle=True, random_state=0)\n",
    "    \n",
    "    train_x_copy = train_x.copy()\n",
    "    if scale == True:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_x_copy.values)\n",
    "        train_x = pd.DataFrame(scaler.transform(train_x), columns=train_x.columns)\n",
    "        test_x = pd.DataFrame(scaler.transform(test_x), columns=test_x.columns)\n",
    "\n",
    "    if polyfeature == True:\n",
    "        polynomial_features = PolynomialFeatures(degree=3)  \n",
    "        train_x = pd.DataFrame(polynomial_features.fit_transform(train_x))\n",
    "        test_x = pd.DataFrame(polynomial_features.fit_transform(test_x))\n",
    "        \n",
    "    data_x = pd.concat([train_x, test_x], axis=0)\n",
    "    data_y = pd.concat([train_y, test_y], axis=0)\n",
    "    \n",
    "    print(data_x.columns)\n",
    "    \n",
    "    return train_x,test_x, train_y, test_y, data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age           int64\n",
      "sex           int64\n",
      "bmi         float64\n",
      "children      int64\n",
      "smoker        int64\n",
      "region       object\n",
      "expenses    float64\n",
      "dtype: object\n",
      "RangeIndex(start=0, stop=220, step=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1003, 220), (335, 220), (1003,), (335,), (1338, 220), (1338,))"
      ]
     },
     "execution_count": 891,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x,test_x, train_y, test_y, data_x, data_y = preprocess_my_data(data,scale = True, polyfeature = True)\n",
    "train_x.shape,test_x.shape, train_y.shape, test_y.shape, data_x.shape, data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.51485</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-0.18005</td>\n",
       "      <td>-0.06361</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>-0.54240</td>\n",
       "      <td>-0.55777</td>\n",
       "      <td>1.62298</td>\n",
       "      <td>-0.59309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17353</td>\n",
       "      <td>0.50493</td>\n",
       "      <td>-0.18452</td>\n",
       "      <td>-1.46921</td>\n",
       "      <td>0.53689</td>\n",
       "      <td>-0.19620</td>\n",
       "      <td>4.27502</td>\n",
       "      <td>-1.56223</td>\n",
       "      <td>0.57089</td>\n",
       "      <td>-0.20862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.54875</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-1.39983</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>1.84367</td>\n",
       "      <td>-0.55777</td>\n",
       "      <td>-0.61615</td>\n",
       "      <td>-0.59309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17353</td>\n",
       "      <td>-0.19169</td>\n",
       "      <td>-0.18452</td>\n",
       "      <td>-0.21175</td>\n",
       "      <td>-0.20383</td>\n",
       "      <td>-0.19620</td>\n",
       "      <td>-0.23392</td>\n",
       "      <td>-0.22516</td>\n",
       "      <td>-0.21673</td>\n",
       "      <td>-0.20862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.43992</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>-0.98254</td>\n",
       "      <td>-0.06361</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>-0.54240</td>\n",
       "      <td>-0.55777</td>\n",
       "      <td>-0.61615</td>\n",
       "      <td>1.68609</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17353</td>\n",
       "      <td>-0.19169</td>\n",
       "      <td>0.52456</td>\n",
       "      <td>-0.21175</td>\n",
       "      <td>0.57946</td>\n",
       "      <td>-1.58570</td>\n",
       "      <td>-0.23392</td>\n",
       "      <td>0.64011</td>\n",
       "      <td>-1.75166</td>\n",
       "      <td>4.79342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.36876</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-1.01464</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>-1.98517</td>\n",
       "      <td>-0.54240</td>\n",
       "      <td>-0.55777</td>\n",
       "      <td>1.62298</td>\n",
       "      <td>-0.59309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17353</td>\n",
       "      <td>0.50493</td>\n",
       "      <td>-0.18452</td>\n",
       "      <td>-1.46921</td>\n",
       "      <td>0.53689</td>\n",
       "      <td>-0.19620</td>\n",
       "      <td>4.27502</td>\n",
       "      <td>-1.56223</td>\n",
       "      <td>0.57089</td>\n",
       "      <td>-0.20862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.94181</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-1.36773</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>-0.54240</td>\n",
       "      <td>1.79284</td>\n",
       "      <td>-0.61615</td>\n",
       "      <td>-0.59309</td>\n",
       "      <td>...</td>\n",
       "      <td>5.76271</td>\n",
       "      <td>-1.98049</td>\n",
       "      <td>-1.90635</td>\n",
       "      <td>0.68064</td>\n",
       "      <td>0.65516</td>\n",
       "      <td>0.63064</td>\n",
       "      <td>-0.23392</td>\n",
       "      <td>-0.22516</td>\n",
       "      <td>-0.21673</td>\n",
       "      <td>-0.20862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.87065</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>-0.75784</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>1.84367</td>\n",
       "      <td>-0.55777</td>\n",
       "      <td>-0.61615</td>\n",
       "      <td>-0.59309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17353</td>\n",
       "      <td>-0.19169</td>\n",
       "      <td>-0.18452</td>\n",
       "      <td>-0.21175</td>\n",
       "      <td>-0.20383</td>\n",
       "      <td>-0.19620</td>\n",
       "      <td>-0.23392</td>\n",
       "      <td>-0.22516</td>\n",
       "      <td>-0.21673</td>\n",
       "      <td>-0.20862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.19673</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>0.84713</td>\n",
       "      <td>0.76493</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>-0.54240</td>\n",
       "      <td>-0.55777</td>\n",
       "      <td>1.62298</td>\n",
       "      <td>-0.59309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17353</td>\n",
       "      <td>0.50493</td>\n",
       "      <td>-0.18452</td>\n",
       "      <td>-1.46921</td>\n",
       "      <td>0.53689</td>\n",
       "      <td>-0.19620</td>\n",
       "      <td>4.27502</td>\n",
       "      <td>-1.56223</td>\n",
       "      <td>0.57089</td>\n",
       "      <td>-0.20862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.05442</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>-0.90229</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>-0.54240</td>\n",
       "      <td>-0.55777</td>\n",
       "      <td>1.62298</td>\n",
       "      <td>-0.59309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17353</td>\n",
       "      <td>0.50493</td>\n",
       "      <td>-0.18452</td>\n",
       "      <td>-1.46921</td>\n",
       "      <td>0.53689</td>\n",
       "      <td>-0.19620</td>\n",
       "      <td>4.27502</td>\n",
       "      <td>-1.56223</td>\n",
       "      <td>0.57089</td>\n",
       "      <td>-0.20862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.43992</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>0.76688</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>-0.54240</td>\n",
       "      <td>1.79284</td>\n",
       "      <td>-0.61615</td>\n",
       "      <td>-0.59309</td>\n",
       "      <td>...</td>\n",
       "      <td>5.76271</td>\n",
       "      <td>-1.98049</td>\n",
       "      <td>-1.90635</td>\n",
       "      <td>0.68064</td>\n",
       "      <td>0.65516</td>\n",
       "      <td>0.63064</td>\n",
       "      <td>-0.23392</td>\n",
       "      <td>-0.22516</td>\n",
       "      <td>-0.21673</td>\n",
       "      <td>-0.20862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.44369</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-1.96157</td>\n",
       "      <td>-0.06361</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>-0.54240</td>\n",
       "      <td>-0.55777</td>\n",
       "      <td>-0.61615</td>\n",
       "      <td>1.68609</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17353</td>\n",
       "      <td>-0.19169</td>\n",
       "      <td>0.52456</td>\n",
       "      <td>-0.21175</td>\n",
       "      <td>0.57946</td>\n",
       "      <td>-1.58570</td>\n",
       "      <td>-0.23392</td>\n",
       "      <td>0.64011</td>\n",
       "      <td>-1.75166</td>\n",
       "      <td>4.79342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1003 rows × 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2        3        4        5        6        7    \\\n",
       "0    1.00000 -0.51485 -0.98516 -0.18005 -0.06361  0.50374 -0.54240 -0.55777   \n",
       "1    1.00000  1.54875 -0.98516 -1.39983 -0.89214  0.50374  1.84367 -0.55777   \n",
       "2    1.00000 -1.43992  1.01507 -0.98254 -0.06361  0.50374 -0.54240 -0.55777   \n",
       "3    1.00000 -1.36876 -0.98516 -1.01464 -0.89214 -1.98517 -0.54240 -0.55777   \n",
       "4    1.00000 -0.94181 -0.98516 -1.36773 -0.89214  0.50374 -0.54240  1.79284   \n",
       "...      ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "998  1.00000 -0.87065  1.01507 -0.75784 -0.89214  0.50374  1.84367 -0.55777   \n",
       "999  1.00000  0.19673  1.01507  0.84713  0.76493  0.50374 -0.54240 -0.55777   \n",
       "1000 1.00000  0.05442  1.01507 -0.90229 -0.89214  0.50374 -0.54240 -0.55777   \n",
       "1001 1.00000 -1.43992  1.01507  0.76688 -0.89214  0.50374 -0.54240  1.79284   \n",
       "1002 1.00000 -0.44369 -0.98516 -1.96157 -0.06361  0.50374 -0.54240 -0.55777   \n",
       "\n",
       "          8        9    ...      210      211      212      213      214  \\\n",
       "0     1.62298 -0.59309  ... -0.17353  0.50493 -0.18452 -1.46921  0.53689   \n",
       "1    -0.61615 -0.59309  ... -0.17353 -0.19169 -0.18452 -0.21175 -0.20383   \n",
       "2    -0.61615  1.68609  ... -0.17353 -0.19169  0.52456 -0.21175  0.57946   \n",
       "3     1.62298 -0.59309  ... -0.17353  0.50493 -0.18452 -1.46921  0.53689   \n",
       "4    -0.61615 -0.59309  ...  5.76271 -1.98049 -1.90635  0.68064  0.65516   \n",
       "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "998  -0.61615 -0.59309  ... -0.17353 -0.19169 -0.18452 -0.21175 -0.20383   \n",
       "999   1.62298 -0.59309  ... -0.17353  0.50493 -0.18452 -1.46921  0.53689   \n",
       "1000  1.62298 -0.59309  ... -0.17353  0.50493 -0.18452 -1.46921  0.53689   \n",
       "1001 -0.61615 -0.59309  ...  5.76271 -1.98049 -1.90635  0.68064  0.65516   \n",
       "1002 -0.61615  1.68609  ... -0.17353 -0.19169  0.52456 -0.21175  0.57946   \n",
       "\n",
       "          215      216      217      218      219  \n",
       "0    -0.19620  4.27502 -1.56223  0.57089 -0.20862  \n",
       "1    -0.19620 -0.23392 -0.22516 -0.21673 -0.20862  \n",
       "2    -1.58570 -0.23392  0.64011 -1.75166  4.79342  \n",
       "3    -0.19620  4.27502 -1.56223  0.57089 -0.20862  \n",
       "4     0.63064 -0.23392 -0.22516 -0.21673 -0.20862  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "998  -0.19620 -0.23392 -0.22516 -0.21673 -0.20862  \n",
       "999  -0.19620  4.27502 -1.56223  0.57089 -0.20862  \n",
       "1000 -0.19620  4.27502 -1.56223  0.57089 -0.20862  \n",
       "1001  0.63064 -0.23392 -0.22516 -0.21673 -0.20862  \n",
       "1002 -1.58570 -0.23392  0.64011 -1.75166  4.79342  \n",
       "\n",
       "[1003 rows x 220 columns]"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"                     Linear Regression\": LinearRegression(),\n",
    "    \"                   K-Nearest Neighbors\": KNeighborsRegressor(),\n",
    "    \"                        Neural Network\": MLPRegressor(),\n",
    "    \"Support Vector Machine (Linear Kernel)\": LinearSVR(),\n",
    "    \"   Support Vector Machine (RBF Kernel)\": SVR(),\n",
    "    \"                         Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"                         Random Forest\": RandomForestRegressor(),\n",
    "    \"                     Gradient Boosting\": GradientBoostingRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_summary(model, model_name, cvn=20):\n",
    "    \n",
    "    print(model_name)\n",
    "    \n",
    "    y_pred_model_train = model.predict(train_x)\n",
    "    y_pred_model_test = model.predict(test_x)\n",
    "    \n",
    "    accuracy_model_train = r2_score(train_y, y_pred_model_train)\n",
    "    print(\"Training Accuracy: \", accuracy_model_train)\n",
    "    \n",
    "    accuracy_model_test = r2_score(test_y, y_pred_model_test)\n",
    "    print(\"Testing Accuracy: \", accuracy_model_test)\n",
    "    \n",
    "    RMSE_model_train = sqrt(mean_squared_error(train_y, y_pred_model_train))\n",
    "    print(\"RMSE for Training Data: \", RMSE_model_train)\n",
    "    \n",
    "    RMSE_model_test = sqrt(mean_squared_error(test_y, y_pred_model_test))\n",
    "    print(\"RMSE for Testing Data: \", RMSE_model_test)\n",
    "    \n",
    "    y_pred_cv_model = cross_val_predict(model, data_x, data_y, cv=cvn)\n",
    "    accuracy_cv_model = r2_score(data_y, y_pred_cv_model)\n",
    "    print(\"Accuracy for\", cvn,\"- Fold Cross Predicted: \", accuracy_cv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Linear Regression trained.\n",
      "                   K-Nearest Neighbors trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Neural Network trained.\n",
      "Support Vector Machine (Linear Kernel) trained.\n",
      "   Support Vector Machine (RBF Kernel) trained.\n",
      "                         Decision Tree trained.\n",
      "                         Random Forest trained.\n",
      "                     Gradient Boosting trained.\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(train_x, train_y)\n",
    "    print(name + \" trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Linear Regression\n",
      "Training Accuracy:  0.8432726770198031\n",
      "Testing Accuracy:  0.8623318488726837\n",
      "RMSE for Training Data:  4732.361579904418\n",
      "RMSE for Testing Data:  4655.504094371313\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.8272064069440559\n",
      "                   K-Nearest Neighbors\n",
      "Training Accuracy:  0.8443574653320628\n",
      "Testing Accuracy:  0.8335135385089941\n",
      "RMSE for Training Data:  4715.955619597897\n",
      "RMSE for Testing Data:  5119.640127937328\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.7890304329898132\n",
      "                        Neural Network\n",
      "Training Accuracy:  -0.2824947697815319\n",
      "Testing Accuracy:  -0.25108028513013614\n",
      "RMSE for Training Data:  13537.3408328235\n",
      "RMSE for Testing Data:  14034.358404165494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 20 - Fold Cross Predicted:  0.19877669515625684\n",
      "Support Vector Machine (Linear Kernel)\n",
      "Training Accuracy:  0.5835310602328199\n",
      "Testing Accuracy:  0.6308119404808208\n",
      "RMSE for Training Data:  7714.306157320669\n",
      "RMSE for Testing Data:  7623.840401975987\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.6475386144539015\n",
      "   Support Vector Machine (RBF Kernel)\n",
      "Training Accuracy:  -0.09308208648872829\n",
      "Testing Accuracy:  -0.09471123023235006\n",
      "RMSE for Training Data:  12497.753385427415\n",
      "RMSE for Testing Data:  13128.036020672389\n",
      "Accuracy for 20 - Fold Cross Predicted:  -0.10080778579105854\n",
      "                         Decision Tree\n",
      "Training Accuracy:  0.9994547913426406\n",
      "Testing Accuracy:  0.7535835921689917\n",
      "RMSE for Training Data:  279.11741463181363\n",
      "RMSE for Testing Data:  6228.518864184397\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.6871260921990181\n",
      "                         Random Forest\n",
      "Training Accuracy:  0.9745244281579322\n",
      "Testing Accuracy:  0.8737126816821208\n",
      "RMSE for Training Data:  1907.9523870362864\n",
      "RMSE for Testing Data:  4458.921674368369\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.8364313884665487\n",
      "                     Gradient Boosting\n",
      "Training Accuracy:  0.9315309723091715\n",
      "Testing Accuracy:  0.8670993319476615\n",
      "RMSE for Training Data:  3127.89843200407\n",
      "RMSE for Testing Data:  4574.183205232021\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.8451985990389655\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model_summary(model, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['region'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age           int64\n",
      "sex           int64\n",
      "bmi         float64\n",
      "children      int64\n",
      "smoker        int64\n",
      "expenses    float64\n",
      "dtype: object\n",
      "RangeIndex(start=0, stop=56, step=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1003, 56), (335, 56), (1003,), (335,), (1338, 56), (1338,))"
      ]
     },
     "execution_count": 884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x,test_x, train_y, test_y, data_x, data_y = preprocess_my_data(data,scale = True, polyfeature = True)\n",
    "train_x.shape,test_x.shape, train_y.shape, test_y.shape, data_x.shape, data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.51485</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-0.18005</td>\n",
       "      <td>-0.06361</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>0.26507</td>\n",
       "      <td>0.50721</td>\n",
       "      <td>0.09270</td>\n",
       "      <td>0.03275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00584</td>\n",
       "      <td>-0.00206</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>-0.00073</td>\n",
       "      <td>0.00577</td>\n",
       "      <td>-0.04569</td>\n",
       "      <td>-0.00026</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>-0.01614</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.54875</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-1.39983</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>2.39861</td>\n",
       "      <td>-1.52576</td>\n",
       "      <td>-2.16798</td>\n",
       "      <td>-1.38170</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.74301</td>\n",
       "      <td>-1.74818</td>\n",
       "      <td>0.98709</td>\n",
       "      <td>-1.11416</td>\n",
       "      <td>0.62909</td>\n",
       "      <td>-0.35521</td>\n",
       "      <td>-0.71008</td>\n",
       "      <td>0.40093</td>\n",
       "      <td>-0.22638</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.43992</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>-0.98254</td>\n",
       "      <td>-0.06361</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>2.07336</td>\n",
       "      <td>-1.46161</td>\n",
       "      <td>1.41477</td>\n",
       "      <td>0.09159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.94852</td>\n",
       "      <td>-0.06140</td>\n",
       "      <td>0.48630</td>\n",
       "      <td>-0.00398</td>\n",
       "      <td>0.03148</td>\n",
       "      <td>-0.24932</td>\n",
       "      <td>-0.00026</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>-0.01614</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.36876</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-1.01464</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>-1.98517</td>\n",
       "      <td>1.87350</td>\n",
       "      <td>1.34844</td>\n",
       "      <td>1.38879</td>\n",
       "      <td>1.22113</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.04456</td>\n",
       "      <td>-0.91845</td>\n",
       "      <td>-2.04371</td>\n",
       "      <td>-0.80757</td>\n",
       "      <td>-1.79698</td>\n",
       "      <td>-3.99857</td>\n",
       "      <td>-0.71008</td>\n",
       "      <td>-1.58004</td>\n",
       "      <td>-3.51584</td>\n",
       "      <td>-7.82332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.94181</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-1.36773</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>0.88700</td>\n",
       "      <td>0.92782</td>\n",
       "      <td>1.28814</td>\n",
       "      <td>0.84023</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.55860</td>\n",
       "      <td>-1.66893</td>\n",
       "      <td>0.94233</td>\n",
       "      <td>-1.08861</td>\n",
       "      <td>0.61467</td>\n",
       "      <td>-0.34706</td>\n",
       "      <td>-0.71008</td>\n",
       "      <td>0.40093</td>\n",
       "      <td>-0.22638</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.87065</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>-0.75784</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>0.75803</td>\n",
       "      <td>-0.88377</td>\n",
       "      <td>0.65981</td>\n",
       "      <td>0.77674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.43525</td>\n",
       "      <td>-0.51238</td>\n",
       "      <td>0.28931</td>\n",
       "      <td>-0.60318</td>\n",
       "      <td>0.34058</td>\n",
       "      <td>-0.19230</td>\n",
       "      <td>-0.71008</td>\n",
       "      <td>0.40093</td>\n",
       "      <td>-0.22638</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.19673</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>0.84713</td>\n",
       "      <td>0.76493</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>0.03870</td>\n",
       "      <td>0.19970</td>\n",
       "      <td>0.16666</td>\n",
       "      <td>0.15049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60793</td>\n",
       "      <td>0.54894</td>\n",
       "      <td>0.36150</td>\n",
       "      <td>0.49567</td>\n",
       "      <td>0.32642</td>\n",
       "      <td>0.21496</td>\n",
       "      <td>0.44758</td>\n",
       "      <td>0.29475</td>\n",
       "      <td>0.19410</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.05442</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>-0.90229</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>0.00296</td>\n",
       "      <td>0.05524</td>\n",
       "      <td>-0.04910</td>\n",
       "      <td>-0.04855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.73458</td>\n",
       "      <td>-0.72632</td>\n",
       "      <td>0.41010</td>\n",
       "      <td>-0.71815</td>\n",
       "      <td>0.40549</td>\n",
       "      <td>-0.22896</td>\n",
       "      <td>-0.71008</td>\n",
       "      <td>0.40093</td>\n",
       "      <td>-0.22638</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.43992</td>\n",
       "      <td>1.01507</td>\n",
       "      <td>0.76688</td>\n",
       "      <td>-0.89214</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>2.07336</td>\n",
       "      <td>-1.46161</td>\n",
       "      <td>-1.10425</td>\n",
       "      <td>1.28461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45101</td>\n",
       "      <td>-0.52468</td>\n",
       "      <td>0.29625</td>\n",
       "      <td>0.61038</td>\n",
       "      <td>-0.34464</td>\n",
       "      <td>0.19460</td>\n",
       "      <td>-0.71008</td>\n",
       "      <td>0.40093</td>\n",
       "      <td>-0.22638</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.44369</td>\n",
       "      <td>-0.98516</td>\n",
       "      <td>-1.96157</td>\n",
       "      <td>-0.06361</td>\n",
       "      <td>0.50374</td>\n",
       "      <td>0.19687</td>\n",
       "      <td>0.43711</td>\n",
       "      <td>0.87034</td>\n",
       "      <td>0.02822</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.54767</td>\n",
       "      <td>-0.24474</td>\n",
       "      <td>1.93826</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>0.06285</td>\n",
       "      <td>-0.49775</td>\n",
       "      <td>-0.00026</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>-0.01614</td>\n",
       "      <td>0.12782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1003 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1        2        3        4        5       6        7   \\\n",
       "0    1.00000 -0.51485 -0.98516 -0.18005 -0.06361  0.50374 0.26507  0.50721   \n",
       "1    1.00000  1.54875 -0.98516 -1.39983 -0.89214  0.50374 2.39861 -1.52576   \n",
       "2    1.00000 -1.43992  1.01507 -0.98254 -0.06361  0.50374 2.07336 -1.46161   \n",
       "3    1.00000 -1.36876 -0.98516 -1.01464 -0.89214 -1.98517 1.87350  1.34844   \n",
       "4    1.00000 -0.94181 -0.98516 -1.36773 -0.89214  0.50374 0.88700  0.92782   \n",
       "...      ...      ...      ...      ...      ...      ...     ...      ...   \n",
       "998  1.00000 -0.87065  1.01507 -0.75784 -0.89214  0.50374 0.75803 -0.88377   \n",
       "999  1.00000  0.19673  1.01507  0.84713  0.76493  0.50374 0.03870  0.19970   \n",
       "1000 1.00000  0.05442  1.01507 -0.90229 -0.89214  0.50374 0.00296  0.05524   \n",
       "1001 1.00000 -1.43992  1.01507  0.76688 -0.89214  0.50374 2.07336 -1.46161   \n",
       "1002 1.00000 -0.44369 -0.98516 -1.96157 -0.06361  0.50374 0.19687  0.43711   \n",
       "\n",
       "           8        9   ...       46       47       48       49       50  \\\n",
       "0     0.09270  0.03275  ... -0.00584 -0.00206  0.01633 -0.00073  0.00577   \n",
       "1    -2.16798 -1.38170  ... -2.74301 -1.74818  0.98709 -1.11416  0.62909   \n",
       "2     1.41477  0.09159  ... -0.94852 -0.06140  0.48630 -0.00398  0.03148   \n",
       "3     1.38879  1.22113  ... -1.04456 -0.91845 -2.04371 -0.80757 -1.79698   \n",
       "4     1.28814  0.84023  ... -2.55860 -1.66893  0.94233 -1.08861  0.61467   \n",
       "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "998   0.65981  0.77674  ... -0.43525 -0.51238  0.28931 -0.60318  0.34058   \n",
       "999   0.16666  0.15049  ...  0.60793  0.54894  0.36150  0.49567  0.32642   \n",
       "1000 -0.04910 -0.04855  ... -0.73458 -0.72632  0.41010 -0.71815  0.40549   \n",
       "1001 -1.10425  1.28461  ...  0.45101 -0.52468  0.29625  0.61038 -0.34464   \n",
       "1002  0.87034  0.02822  ... -7.54767 -0.24474  1.93826 -0.00794  0.06285   \n",
       "\n",
       "           51       52       53       54       55  \n",
       "0    -0.04569 -0.00026  0.00204 -0.01614  0.12782  \n",
       "1    -0.35521 -0.71008  0.40093 -0.22638  0.12782  \n",
       "2    -0.24932 -0.00026  0.00204 -0.01614  0.12782  \n",
       "3    -3.99857 -0.71008 -1.58004 -3.51584 -7.82332  \n",
       "4    -0.34706 -0.71008  0.40093 -0.22638  0.12782  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "998  -0.19230 -0.71008  0.40093 -0.22638  0.12782  \n",
       "999   0.21496  0.44758  0.29475  0.19410  0.12782  \n",
       "1000 -0.22896 -0.71008  0.40093 -0.22638  0.12782  \n",
       "1001  0.19460 -0.71008  0.40093 -0.22638  0.12782  \n",
       "1002 -0.49775 -0.00026  0.00204 -0.01614  0.12782  \n",
       "\n",
       "[1003 rows x 56 columns]"
      ]
     },
     "execution_count": 885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Linear Regression trained.\n",
      "                   K-Nearest Neighbors trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Neural Network trained.\n",
      "Support Vector Machine (Linear Kernel) trained.\n",
      "   Support Vector Machine (RBF Kernel) trained.\n",
      "                         Decision Tree trained.\n",
      "                         Random Forest trained.\n",
      "                     Gradient Boosting trained.\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(train_x, train_y)\n",
    "    print(name + \" trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Linear Regression\n",
      "Training Accuracy:  0.8355466992767058\n",
      "Testing Accuracy:  0.8814078014426706\n",
      "RMSE for Training Data:  4847.600921326647\n",
      "RMSE for Testing Data:  4320.937984245219\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.8385819063721809\n",
      "                   K-Nearest Neighbors\n",
      "Training Accuracy:  0.85440972069296\n",
      "Testing Accuracy:  0.8589526304010063\n",
      "RMSE for Training Data:  4561.122659922318\n",
      "RMSE for Testing Data:  4712.2949810263635\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.8128251841533437\n",
      "                        Neural Network\n",
      "Training Accuracy:  -0.6193301227826709\n",
      "Testing Accuracy:  -0.5464413191083968\n",
      "RMSE for Training Data:  15211.542648528124\n",
      "RMSE for Testing Data:  15603.308509906015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 20 - Fold Cross Predicted:  -0.3299937935973145\n",
      "Support Vector Machine (Linear Kernel)\n",
      "Training Accuracy:  0.33372023384522387\n",
      "Testing Accuracy:  0.3970913167078851\n",
      "RMSE for Training Data:  9757.394727444922\n",
      "RMSE for Testing Data:  9742.61952104642\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.48237299675825374\n",
      "   Support Vector Machine (RBF Kernel)\n",
      "Training Accuracy:  -0.09113611350490647\n",
      "Testing Accuracy:  -0.09261516825444982\n",
      "RMSE for Training Data:  12486.623789344103\n",
      "RMSE for Testing Data:  13115.461763227693\n",
      "Accuracy for 20 - Fold Cross Predicted:  -0.09593033699255282\n",
      "                         Decision Tree\n",
      "Training Accuracy:  0.9994530805400387\n",
      "Testing Accuracy:  0.6822933978939467\n",
      "RMSE for Training Data:  279.5549909455425\n",
      "RMSE for Testing Data:  7072.339378299368\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.6907212445463851\n",
      "                         Random Forest\n",
      "Training Accuracy:  0.9727396372930913\n",
      "Testing Accuracy:  0.8721678211968332\n",
      "RMSE for Training Data:  1973.655626498423\n",
      "RMSE for Testing Data:  4486.111551979519\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.8323549779712611\n",
      "                     Gradient Boosting\n",
      "Training Accuracy:  0.9176479621568104\n",
      "Testing Accuracy:  0.887985886890434\n",
      "RMSE for Training Data:  3430.383994049662\n",
      "RMSE for Testing Data:  4199.391310967829\n",
      "Accuracy for 20 - Fold Cross Predicted:  0.8499778836497038\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model_summary(model, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
